{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e43a7-6a52-4901-97f3-d109de0c51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GOOSE_SemanticDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Example Pytorch Dataset Module for semantic tasks with GOOSE.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_dict: List[Dict], crop: bool = True, resize_size: Iterable[int] = None):\n",
    "        '''\n",
    "        Parameters:\n",
    "            dataset_dict  [Iter]    : List of  Dicts with the images information generated by *goose_create_dataDict*\n",
    "\n",
    "            crop          [Bool]    : Whether to make a square crop of the images or not\n",
    "\n",
    "            resize_size   [Iter]    : List with the target resize size of the images (After the crop if crop == True)\n",
    "        '''\n",
    "        self.dataset_dict   = dataset_dict\n",
    "        self.transforms     = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])\n",
    "        self.resize_size    = resize_size\n",
    "        self.crop           = crop\n",
    "\n",
    "    def preprocess(self, image):\n",
    "        if image is None:\n",
    "            return None\n",
    "\n",
    "        if self.crop:\n",
    "            # Square-Crop in the center\n",
    "            s = min([image.width , image.height])\n",
    "            image = transforms.CenterCrop((s,s)).forward(image)\n",
    "\n",
    "        if self.resize_size is not None:\n",
    "            # Resize to given size\n",
    "            image = image.resize(self.resize_size, resample=Image.NEAREST)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        '''\n",
    "        Parameter:\n",
    "            i   [int]                   : Index of the image to get\n",
    "\n",
    "        Returns:\n",
    "            image_tensor [torch.Tensor] : 3 x H x W Tensor\n",
    "\n",
    "            label_tensor [torch.Tensor] : H x W Tensor as semantic map\n",
    "        '''\n",
    "        image = Image.open(self.dataset_dict[i]['img_path']).convert('RGB')\n",
    "        label = Image.open(self.dataset_dict[i]['semantic_path']).convert('L')\n",
    "\n",
    "        image = self.preprocess(image)\n",
    "        label = self.preprocess(label)\n",
    "\n",
    "        image_tensor = self.transforms(image)\n",
    "        label_tensor = torch.from_numpy(np.array(label)).long()\n",
    "\n",
    "        return image_tensor, label_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
